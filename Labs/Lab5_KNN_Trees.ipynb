{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab5: $K$-Nearest Neighbors & Decision Trees**\n",
    "\n",
    "**Course**: **CSCI-866-001: Data Mining & Knowledge Discovery** <br>\n",
    "**Lecturer**: **Sothea HAS, PhD**\n",
    "\n",
    "-----\n",
    "\n",
    "**Objective:** In this lab, we will explore nonparametric models that predict the label of a data point based on its similarity to training examples. Additionally, we will examine strategies to enhance model performance by applying cross-validation to fine-tune hyperparameters, ensuring optimal predictive accuracy.\n",
    "\n",
    "- The `notebook` of this `Lab` can be downloaded here: [Lab5_KNN_Trees.ipynb](https://hassothea.github.io/Data_Analysis_AUPP/Labs/Lab5_KNN_Trees.ipynb){target=\"_blank\"}.\n",
    "\n",
    "- Or you can work directly with `Google Colab` here: [Lab5_KNN_Trees.ipynb](https://colab.research.google.com/drive/1AZNwrnmvJWdkXzQuhZwfwi64PWMXi0vh?usp=sharing){target=\"_blank\"}.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Email Spam Dataset**\n",
    "\n",
    "Let's start by exploring the `email spam dataset` introduced in the previous [chapter](https://hassothea.github.io/Data_Mining_AUPP/Classification_NBC_and_Logistic_Reg.html). The data can be imported as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>num3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>charSemicolon</th>\n",
       "      <th>charRoundbracket</th>\n",
       "      <th>charSquarebracket</th>\n",
       "      <th>charExclamation</th>\n",
       "      <th>charDollar</th>\n",
       "      <th>charHash</th>\n",
       "      <th>capitalAve</th>\n",
       "      <th>capitalLong</th>\n",
       "      <th>capitalTotal</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  make  address   all  num3d   our  over  remove  internet  order  ...  \\\n",
       "0   1  0.00     0.64  0.64    0.0  0.32  0.00    0.00      0.00   0.00  ...   \n",
       "1   2  0.21     0.28  0.50    0.0  0.14  0.28    0.21      0.07   0.00  ...   \n",
       "2   3  0.06     0.00  0.71    0.0  1.23  0.19    0.19      0.12   0.64  ...   \n",
       "3   4  0.00     0.00  0.00    0.0  0.63  0.00    0.31      0.63   0.31  ...   \n",
       "4   5  0.00     0.00  0.00    0.0  0.63  0.00    0.31      0.63   0.31  ...   \n",
       "\n",
       "   charSemicolon  charRoundbracket  charSquarebracket  charExclamation  \\\n",
       "0           0.00             0.000                0.0            0.778   \n",
       "1           0.00             0.132                0.0            0.372   \n",
       "2           0.01             0.143                0.0            0.276   \n",
       "3           0.00             0.137                0.0            0.137   \n",
       "4           0.00             0.135                0.0            0.135   \n",
       "\n",
       "   charDollar  charHash  capitalAve  capitalLong  capitalTotal  type  \n",
       "0       0.000     0.000       3.756           61           278  spam  \n",
       "1       0.180     0.048       5.114          101          1028  spam  \n",
       "2       0.184     0.010       9.821          485          2259  spam  \n",
       "3       0.000     0.000       3.537           40           191  spam  \n",
       "4       0.000     0.000       3.537           40           191  spam  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/hassothea/MLcourses/main/data/spam.txt\"\n",
    "data = pd.read_csv(path, sep=\" \")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Univariate Analysis: Preprocessing & Data Analysis**\n",
    "\n",
    "A. Visualize the distribution of the target `type`.\n",
    "\n",
    "B. Compute minimum values of all features and check that all of them are positive.\n",
    "\n",
    "C. Are there any `nan` or `NA` values in this dataset?\n",
    "\n",
    "D. Are their any duplicated observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Bivariate Analysis: Exploratory Data Analysis & Important Feature Detection**\n",
    "\n",
    "A. Pick three input features and visualize heir relationship with the target `type`. Do the chosen inputs seem to be related with the target.\n",
    "\n",
    "B. Trying to visualize or detect the connection between all 57 inputs to the target is a challenging task. To this purpose, statistical tests such as [Analysis of Variance or `ANOVA`](https://en.wikipedia.org/wiki/Analysis_of_variance) and its nonparemetric version ([Kruskal-Wallis Test](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test)) are the useful tools. We will use [Kruskal-Wallis Test](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test) to detect informative inputs for email classification.\n",
    "\n",
    "- Import `kruskal` function from `scipy.stats` as follow: \n",
    "    \n",
    "    ```\n",
    "    from scipy.stats import kruskal\n",
    "    ```\n",
    "\n",
    "- For each of the three selected input features in the first point, perform the `kruskal-wallis` test to check if the median among `spam` and `nonspam` group of the considered input significantly different.\n",
    "\n",
    "- Conduct the Kruskal-Wallis test on all 57 columns of the dataset to assess whether there are significant differences in the medians of input features between the `spam` and `nonspam` groups.\n",
    "\n",
    "- Select only the features where the p-value is less than 1e-10, indicating that the difference in medians is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. $K$-Nearest Neighbors (KNN)**\n",
    "\n",
    "### **3.1. Preparation**\n",
    "A. Split the dataset into 80%-20% of training and testing data.\n",
    "\n",
    "B. Standardize both the training and testing input features.\n",
    "\n",
    "C. Choose your favorite $K$ and build two KNN models on the training data using all columns and only the selected features.\n",
    "\n",
    "D. Test the performance of the two models on the testing data using suitable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Fine-tune $K$**\n",
    "A. For each model, perform $K$-fold cross-validation method to select the best $K$.\n",
    "\n",
    "B. Evaluate the performance of the two new models using their respective optimal value of $K$.\n",
    "\n",
    "C. Conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Decision Trees**\n",
    "\n",
    "- **Default setting:** Build two different decision tree methods on the 80% training data. Test the performance of the models on the testing data.\n",
    "- **Fine-tuned model:** Perform cross-validation to tune the hyperparameters of the models including:\n",
    "    - depth of the trees\n",
    "    - minimal size of the terminal nodes (leaves)\n",
    "    - number of features to be considered at each split.\n",
    "    - splitting criteria...\n",
    "- Measure their performance on the corresponding testing dataset.\n",
    "- Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Further Reading**\n",
    "\n",
    "$^{\\text{ðŸ“š}}$  `Pandas` python library: [https://pandas.pydata.org/docs/getting_started/index.html#getting-started](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) <br>\n",
    "$^{\\text{ðŸ“š}}$  `Pandas Cheatsheet`: [https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) <br>\n",
    "$^{\\text{ðŸ“š}}$  `10 Minute to Pandas`: [https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html) <br>\n",
    "$^{\\text{ðŸ“š}}$  `Some Pandas Lession`: [https://www.kaggle.com/learn/pandas](https://pandas.pydata.org/docs/user_guide/10min.html) <br>\n",
    "$^{\\text{ðŸ“š}}$ [Chapter 4, *Introduction to Statistical Learning with R*, James et al. (2021).](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [The Element of Statistical Learning, Hastie et al. (2002)](https://www.stat.ntu.edu.tw/download/æ•™å­¸æ–‡ä»¶/bigdata/The%20Elements%20of%20Statistical%20Learning.pdf){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [A Distribution-free Theory of Nonparameteric Regression, GyÃ¶rfi et al. (2002).](https://link.springer.com/book/10.1007/b97848){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [A Probabilistic Theory of Pattern Recognition, Devroye et al. (1997)](https://www.szit.bme.hu/~gyorfi/pbook.pdf){target=\"_blank\"}. <br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
